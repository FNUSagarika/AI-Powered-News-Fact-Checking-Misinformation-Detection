pip install openai

 pip install langchain

 pip install langchain-pinecone

pip install langchain_openai

 pip install langchain_community

pip install pinecone

pip install openai-chat

pip install google-search-results

pip uninstall pinecone-client

pip install pinecone-client>=3.0.0

!pip install --quiet langchain openai pinecone-client==2.2.1 python-dotenv

pip install --upgrade pinecone-client

# All imports

import os
import requests
#import pinecone

#from pinecone import Pinecone, ServerlessSpec                         # rel: Start
from langchain.embeddings.openai import OpenAIEmbeddings              # rel: Step 2
from langchain.document_loaders import PyPDFLoader                    # rel: Step 3
from langchain.text_splitter import RecursiveCharacterTextSplitter    # rel: Step 3
from langchain.vectorstores import Pinecone as LC_Pinecone            # rel: Step 4
from langchain_openai import OpenAI                                   # rel: Step 5
from langchain.chains import RetrievalQA

!pip install langchain openai wikipedia faiss-cpu scikit-learn

from google.colab import files
uploaded = files.upload()

# Set up API keys and environment variables

OPENAI_API_KEY = "add your api key"
PINECONE_KEY = "add your api key"
PINECONE_REGION = "add your api key"

os.environ["PINECONE_KEY"] = PINECONE_KEY
os.environ["PINECONE_REGION"] = PINECONE_REGION

# ========================
# STEP 4: Load & preprocess LIAR dataset
# ========================
import pandas as pd

def load_liar_dataset(file_path):
    df = pd.read_csv(file_path, sep='\t', header=None, names=[
        "id", "label", "statement", "subject", "speaker", "job_title",
        "state", "party", "barely_true_counts", "false_counts", "half_true_counts",
        "mostly_true_counts", "pants_on_fire_counts", "context"
    ])
    return df[["statement", "label"]]

def preprocess_labels(df):
    binary_map = {
        'false': 'fake',
        'pants-fire': 'fake',
        'barely-true': 'fake',
        'half-true': 'real',
        'mostly-true': 'real',
        'true': 'real'
    }
    df['label'] = df['label'].map(binary_map)
    return df[df['label'].isin(['fake', 'real'])]

def get_train_test_split(train_path, test_path):
    train_df = preprocess_labels(load_liar_dataset(train_path))
    test_df = preprocess_labels(load_liar_dataset(test_path))
    return train_df, test_df




# ========================
# STEP 5: Build Wikipedia RAG Vector Store
# ========================
from langchain.document_loaders import WikipediaLoader
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings

def build_wiki_vector_store(search_terms, api_key):
    documents = []
    for term in search_terms:
        loader = WikipediaLoader(query=term)
        docs = loader.load()
        documents.extend(docs)

    embedding = OpenAIEmbeddings(openai_api_key=api_key)
    vectorstore = FAISS.from_documents(documents, embedding)
    return vectorstore


# ========================
# STEP 6: Setup LangChain QA
# ========================
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

def setup_qa(vectorstore, api_key):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, openai_api_key=api_key)
    return RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())

def ask_model(qa, claim):
    prompt = f"Is the following claim likely fake or real? Just say 'fake' or 'real'. Claim: {claim}"
    response = qa.run(prompt)
    return "fake" if "fake" in response.lower() else "real"


# ========================
# STEP 7: Evaluation Metrics
# ========================
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def evaluate(y_true, y_pred):
    return {
        "accuracy": accuracy_score(y_true, y_pred),
        "precision": precision_score(y_true, y_pred, pos_label="fake"),
        "recall": recall_score(y_true, y_pred, pos_label="fake"),
        "f1_score": f1_score(y_true, y_pred, pos_label="fake")
    }

# STEP 8: Run RAG Pipeline on LIAR dataset
# ========================

# Only run this if you uploaded `train.tsv` and `test.tsv`
try:
    train_df, test_df = get_train_test_split("train.tsv", "test.tsv")
    search_terms = ["Fake news", "Misinformation", "COVID-19 misinformation", "Political disinformation", "Social media"]
    vectorstore = build_wiki_vector_store(search_terms, OPENAI_API_KEY)
    qa = setup_qa(vectorstore, OPENAI_API_KEY)

    sample_test = test_df.sample(30, random_state=42)
    y_true = sample_test['label'].tolist()
    y_pred = [ask_model(qa, claim) for claim in sample_test['statement']]

    metrics = evaluate(y_true, y_pred)

    print("\nüìä Evaluation Metrics:")
    for k, v in metrics.items():
        print(f"{k.capitalize()}: {v:.2f}")
except:
    print("‚ö†Ô∏è Skipping LIAR dataset pipeline ‚Äî train.tsv/test.tsv not uploaded.")


!pip install newspaper3k

!pip install lxml_html_clean

# ========================
# STEP 9: URL-based Fake News Checker (on-demand)
# ========================
from newspaper import Article
from langchain.prompts import PromptTemplate

def extract_text_from_url(url):
    article = Article(url)
    article.download()
    article.parse()
    return article.text

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, openai_api_key=OPENAI_API_KEY)

TEMPLATE = """
You are a fact-checking assistant. Assess the credibility of the following content:

\"\"\"{content}\"\"\"

Respond with one of the following labels: "credible", "potentially misleading", or "fake".
Then briefly explain why.
"""

prompt = PromptTemplate.from_template(TEMPLATE)

def analyze_text(text):
    input_prompt = prompt.format(content=text[:2000])  # Truncate to fit context window
    response = llm.predict(input_prompt)

    if "credible" in response.lower():
        return "credible", response
    elif "misleading" in response.lower():
        return "potentially misleading", response
    else:
        return "fake", response


# ========================
# STEP 10: Run on URL
# ========================
url = input("üì• Paste a URL to analyze: ").strip()
try:
    article_text = extract_text_from_url(url)
    verdict, explanation = analyze_text(article_text)

    print(f"\nüßæ Verdict: {verdict.upper()}\n")
    print("üí¨ Explanation:\n")
    print(explanation)
except Exception as e:
    print(f"‚ùå Error analyzing URL: {e}")

# ========================
# STEP 10: Run on URL
# ========================
url = input("üì• Paste a URL to analyze: ").strip()
try:
    article_text = extract_text_from_url(url)
    verdict, explanation = analyze_text(article_text)

    print(f"\nüßæ Verdict: {verdict.upper()}\n")
    print("üí¨ Explanation:\n")
    print(explanation)
except Exception as e:
    print(f"‚ùå Error analyzing URL: {e}")
